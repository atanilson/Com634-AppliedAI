{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSQQ6re9zCzM"
      },
      "source": [
        "# Exercise (with one solution)\n",
        "\n",
        "From Lab session **4.2** and **4.3**, we know the process for training a classifier based on the neural networks.\n",
        "Now, let's build your own network according to the **4.2** and **4.3**.\n",
        "\n",
        "\n",
        "We use the MNIST dataset to train the networks.\n",
        "\n",
        "# Step 1: Import the libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlTNZnCJzCzU"
      },
      "outputs": [],
      "source": [
        "#import  the libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fsDcIb7zCzX"
      },
      "source": [
        "# Step 2: Load the dataset and visualize the dataset\n",
        "We can load the MNIST dataset from ``torchvision`` with the following parameters:\n",
        "\n",
        " - **root** is the path where the train/test data is stored,\n",
        " - **train** specifies training or test dataset,\n",
        " - **download=True** downloads the data from the internet if itâ€™s not available at root.\n",
        " - **transform** and **target_transform** specify the feature and label transformations\n",
        "\n",
        "\n",
        "Besides, we can index Datasets manually like a list: train_set[index]. We use matplotlib to visualize some samples in our training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42cVuKtgzCza"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "\n",
        "train_set = torchvision.datasets.MNIST(root = './data/MNIST', download = True,\n",
        "                                              train = True, transform = transforms.Compose([transforms.ToTensor(),]))\n",
        "\n",
        "test_set = torchvision.datasets.MNIST(root = './data/MNIST', download=True,\n",
        "                                             train=False, transform = transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "\n",
        "# Visulize some figures\n",
        "figure = plt.figure(figsize=(10, 10))\n",
        "cols, rows = 6, 6\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
        "    img, label = train_set[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    # plt.title(\"Label \"+ str(label))\n",
        "    plt.title(\"Ground Truth:{}\".format(label))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbKKrtY-zCzf"
      },
      "source": [
        "Preparing your data for training with DataLoaders\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOjkLHU_zCzh"
      },
      "outputs": [],
      "source": [
        "# DataLoader with the batch_size\n",
        "print(\"Training data size: {}\".format(len(train_set)))\n",
        "train_size=len(train_set)\n",
        "test_size=len(test_set)\n",
        "print(\"Training data size: {}\".format(len(test_set)))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=20)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a_PvY8GzCzj"
      },
      "source": [
        "# Step 3: Define your own network model\n",
        "\n",
        "Here, you can design any network model to classify the dataset. You can add any layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYfWM_3-zCzp"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# define the model\n",
        "model = NeuralNetwork()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Define Loss and Optimizer\n",
        "\n",
        "Define the loss and the optimizer and their hyper-parameters, such as number of epochs, and learning rate.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4TWRgoWmque9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  you can set epoch size\n",
        "\n",
        "# define learning rate\n",
        "learning_rate = 0.005\n",
        "# define your optimizer with SGD and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "# define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# set the epoch\n",
        "epochs = 15"
      ],
      "metadata": {
        "id": "R2gTprXOqxiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nsBm7fKzCzt"
      },
      "source": [
        "# Step 5: Train your own network model\n",
        "\n",
        "You can set up parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlwY0ihMzCzv"
      },
      "outputs": [],
      "source": [
        "# loop over the dataset multiple times\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  for j,(images,targets) in enumerate(train_loader):\n",
        "\n",
        "    #making predictions\n",
        "    y_pred = model(images)\n",
        "\n",
        "    #calculating loss\n",
        "    loss = criterion(y_pred,targets.reshape(-1))\n",
        "    #backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if i>10:\n",
        "    optimizer.lr = 0.0005\n",
        "  print(loss)\n",
        "  losses.append(loss)\n",
        "\n",
        "print('Complete Training')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Oi6cWvzCz5"
      },
      "source": [
        "# Step 6: Evaluate the result on the test dataset and analyze the performance on the whole dataset\n",
        "\n",
        "You can show the best performance with any update mthods.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEhX3dLtzCz8"
      },
      "outputs": [],
      "source": [
        "# Test the result on test data\n",
        "\n",
        "# make a prediction for a sample randomly chose from the test dataset\n",
        "# you can run this part repeatedly, see the classification result from the model\n",
        "import random\n",
        "rand_no = random.randint(0,10000)\n",
        "print(rand_no)\n",
        "\n",
        "x_test, y_test = next(iter(test_loader))\n",
        "\n",
        "y_pred = (model(x_test).argmax(dim=1))\n",
        "\n",
        "plt.imshow(x_test[rand_no].reshape(28,28),cmap='gray')\n",
        "\n",
        "pred = model(x_test[rand_no].reshape(-1,1,28,28)).argmax()\n",
        "\n",
        "print(\"Prediction is {}\".format(pred))\n",
        "\n",
        "# compute the accuracy of the model\n",
        "\n",
        "print(\"Accuracy is : \",(y_pred.eq(y_test).sum()/test_size).item()*100,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is just another way of visualizing the dataset."
      ],
      "metadata": {
        "id": "pX9RZAtTmaI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ktki2wrRzCz-"
      },
      "outputs": [],
      "source": [
        "# Visulize some test figures\n",
        "figure = plt.figure(figsize=(10, 10))\n",
        "cols, rows = 6, 5\n",
        "for i in range(1, cols * rows + 1):   # for loop to get multiple images to predict (instead of only one)\n",
        "\n",
        "    # getting one image to predict\n",
        "    sample_idx = torch.randint(len(test_set), size=(1,)).item()\n",
        "    print(\"Prediction: {}\".format(sample_idx))\n",
        "\n",
        "    # predict\n",
        "    img, label = test_set[sample_idx]\n",
        "    pred = model(img.reshape(-1,1,28,28)).argmax()\n",
        "\n",
        "    # plot\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(\"Prediction: {}\".format(pred))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, this is another way of processing the test set and computing the metrics.\n",
        "\n",
        "In fact, this is the way we usually do."
      ],
      "metadata": {
        "id": "BUU-RQQaqGxM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gy3eXTtWzC0D"
      },
      "outputs": [],
      "source": [
        "# we also can plot the Confusion Matrix\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# accuracy function\n",
        "def testing_accuracy(model, data_loader):\n",
        "    model.eval()  # IMPORTANT: we use this to prevent the network from learning using the test set\n",
        "    test_loss = 0\n",
        "    device = 'cpu'\n",
        "\n",
        "    y_pred = []\n",
        "    y_actu = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)  # predict\n",
        "            test_loss += criterion(output, target)  # loss - same loss used during training\n",
        "\n",
        "            # get the index of the max log-probability\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            y_pred.extend(torch.flatten(pred).tolist())\n",
        "            y_actu.extend(target.tolist())\n",
        "\n",
        "    y_pred = pd.Series(y_pred, name='Actual')\n",
        "    y_actu = pd.Series(y_actu, name='Predicted')\n",
        "    cm = pd.crosstab(y_actu, y_pred)\n",
        "    correct = sum([cm.iloc[i,i] for i in range(len(cm))])\n",
        "\n",
        "    test_loss /= len(data_loader.dataset)\n",
        "    accuracy = 100*correct/len(test_loader.dataset)\n",
        "\n",
        "    return(test_loss, accuracy, cm)\n",
        "\n",
        "test_results = testing_accuracy(model, test_loader)\n",
        "\n",
        "print(\"- Test Loss: \", test_results[0], \"\\n\")\n",
        "print(\"- Accuracy: \", test_results[1], \"\\n\")\n",
        "print(\"- Confusion Matrix: \\n \\n\",  test_results[2] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sUomUqRzC0D"
      },
      "source": [
        "### Creating Heatmap for Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp0JknPnzC0E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conf_matrix = test_results[2].to_numpy()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "im = ax.imshow(conf_matrix)\n",
        "\n",
        "ax.set_xticks(np.arange(10))\n",
        "ax.set_yticks(np.arange(10))\n",
        "\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        text = ax.text(j, i, conf_matrix[i, j],\n",
        "                       ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "ax.set_xlabel('Actual Labels')\n",
        "ax.set_ylabel('Predicted Labels')\n",
        "ax.set_title('Confusion Matrix')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc9Wq8lVzC0G"
      },
      "source": [
        "# Step 7: Any other thought on the training network?\n",
        " - How to save the training file?\n",
        " - How to speed the training process?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfUbeXEezC0H"
      },
      "outputs": [],
      "source": [
        "#  train on the GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)\n",
        "\n",
        "\n",
        "# save the training model\n",
        "PATH = './mnist_net.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9c37791b62b9d5c239fb0fc5acdaf3bd7e92ad96e6d57cd91101e1e69e5d3005"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
