{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IrBARV9PyDk"
      },
      "source": [
        "# COMP534 Lab session 4\n",
        "In this session, we would like to introduce some metrics for model evaluation firstly. Then we will show how to build neural networks (NNs) model based on [PyTorch](https://pytorch.org/). You also can use other frameworks, like [tensorflow](https://www.tensorflow.org/) or [keras](https://keras.io/). At last, we will show a classification example using Pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V63-fpJFOZr_"
      },
      "source": [
        "\n",
        "# Visualizations with Display Objects\n",
        "\n",
        "In this example, we will construct display objects,\n",
        "`ConfusionMatrixDisplay`, `RocCurveDisplay`, and\n",
        "`PrecisionRecallDisplay` directly from their respective metrics. This\n",
        "is an alternative to using their corresponding plot functions when\n",
        "a model's predictions are already computed or expensive to compute. Note that\n",
        "this is advanced usage, and in general we recommend using their respective\n",
        "plot functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S-lEmb2OZsB"
      },
      "source": [
        "## Load Data and train model\n",
        "For this example, we load a blood transfusion service center data set from\n",
        "OpenML (<https://www.openml.org/d/1464). This is a binary classification\n",
        "problem where the target is whether an individual donated blood. Then the\n",
        "data is split into a train and test dataset and a logistic regression is\n",
        "fitted with the train dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS6m_vy-OZsC"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = fetch_openml(data_id=1464, return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
        "\n",
        "# StandardScale normalizes the features: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "clf = make_pipeline(StandardScaler(), LogisticRegression(random_state=0))\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obHfKYCzOZsD"
      },
      "source": [
        "### `ConfusionMatrixDisplay`\n",
        " With the fitted model, we compute the predictions of the model on the test\n",
        " dataset. These predictions are used to compute the confustion matrix which\n",
        " is plotted with the `ConfusionMatrixDisplay` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s8j_ZDOOZsD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-9nMob8OZsE"
      },
      "source": [
        "### `RocCurveDisplay`\n",
        " The ROC curve requires either the probabilities or the non-thresholded\n",
        " decision values from the estimator. Since the logistic regression provides\n",
        " a decision function, we will use it to plot the ROC curve:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H90vgZFUOZsE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "y_score = clf.decision_function(X_test)  # return the probabilities\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=clf.classes_[1])\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, estimator_name=\"Log Regression\").plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oob8vis_OZsF"
      },
      "source": [
        "### `PrecisionRecallDisplay`\n",
        " Similarly, the precision recall curve can be plotted using `y_score` from\n",
        " the prevision sections.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lC_QDLmOZsF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "\n",
        "prec, recall, _ = precision_recall_curve(y_test, y_score, pos_label=clf.classes_[1])\n",
        "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu5_WhsCOZsG"
      },
      "source": [
        "### Combining the display objects into a single plot\n",
        " The display objects store the computed values that were passed as arguments.\n",
        " This allows for the visualizations to be easliy combined using Matplotlib's\n",
        " API. In the following example, we place the displays next to each other in a\n",
        " row.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NJV5C_OOZsG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
        "\n",
        "roc_display.plot(ax=ax1)  # left: roc curve\n",
        "pr_display.plot(ax=ax2)  # right: precision x recall\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZQoHQhAwkRx"
      },
      "source": [
        "### F-1 Score\n",
        "\n",
        "Another commonly used metric is the F-1 score, which is calculated using precision and recall. Below, we calculate the F1 score using the SKLearn library as well as using precision and recall according to the Equation:\n",
        "\n",
        "$$F_1 = 2 * \\frac{Precision * Recall}{Precision + Recall}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqznnqLAuwmL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, y_pred, pos_label= clf.classes_[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "p = precision_score(y_test, y_pred, pos_label= clf.classes_[1])\n",
        "r = recall_score(y_test, y_pred, pos_label= clf.classes_[1])\n",
        "\n",
        "print(2 * p * r / (p + r))  # f1-score"
      ],
      "metadata": {
        "id": "j-72pmef2J0v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "9c37791b62b9d5c239fb0fc5acdaf3bd7e92ad96e6d57cd91101e1e69e5d3005"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}