{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q18cZM12QpeP"
      },
      "source": [
        "# Fashion MNIST\n",
        "Fashion Mnist is a Dataset created by Zolando Fashion Wear to replace the Original Mnist and at the same time increasing the difficulty.\n",
        "This code post is all about how to create a NN model to classify fashion mnist images.\n",
        "\n",
        "Let’s look at the code.\n",
        "\n",
        "# 1. Import the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FsIGW_lQV-V"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBB6CBulRIuf"
      },
      "source": [
        "# 2. Load the Dataset\n",
        "Pytorch’s torchvision contains inbuilt datasets for practice, such as MNIST, FashionMnist, etc.\n",
        "\n",
        "If the dataset you want to use is NOT within the torchvision library, you will need to implement your own custom dataset. Here is a tutorial on that: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX8tEI55RMfX"
      },
      "outputs": [],
      "source": [
        "#load datatset\n",
        "\n",
        "train_set = torchvision.datasets.FashionMNIST(root = './data/FashionMNIST', download = True,\n",
        "                                              train = True, transform = transforms.Compose([transforms.ToTensor(),]))\n",
        "\n",
        "test_set = torchvision.datasets.FashionMNIST(root = './data/FashionMNIST', download=True,\n",
        "                                             train=False, transform = transforms.Compose([transforms.ToTensor()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmUwI_rfRWJV"
      },
      "source": [
        "Note the parameter `transform`. This receives a list of transformations that needs to be done on the input image as a part of pre-processing (such as normalization/standardization, resize, etc) and can be implemented using `transforms.compose`. This can also be used to introduce some data augmentation in the training pipeline.\n",
        "Please, check here for more details: https://pytorch.org/vision/stable/transforms.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW9QqLjhReAc"
      },
      "source": [
        "`Dataset` (above) class in Pytorch basically covers the data in a tuple and enables us to access the index of each data. It is necessary to create `Dataloader` (below) which can be used to shuffle, apply Mini-Batch Gradient Descent and more.\n",
        "\n",
        "We can also show some figures for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AD6t4fPRW2I"
      },
      "outputs": [],
      "source": [
        "# dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=20)  # this is actually reponsible for returning the mini-batch\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=60000)\n",
        "\n",
        "# iterate the train data with samples\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "#used to create a grid of images\n",
        "grid = torchvision.utils.make_grid(images,nrow=20)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(np.transpose(grid,(1,2,0)),cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Iunr-nRoRN"
      },
      "source": [
        "# 3. Define the Neural Network Model\n",
        "Here, we define the NeuralNetwork as the same as in Lab session **4.2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAwniEtAR9u6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# define the model\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7YSCfoYSA5x"
      },
      "source": [
        "Note: we just define the simple network model with linear function, you can implement any other structures based on the Pytorch framework as we will see in other praticals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mYkZCfPSFVW"
      },
      "source": [
        "# 4. Define Loss and Optimizer\n",
        "\n",
        "Define the loss (in this case Cross-Entropy loss) and the optimizer (SGD with momentum) and their hyper-parameters, such as number of epochs, and learning rate.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2BnIJ19SCcw"
      },
      "outputs": [],
      "source": [
        "# define learning rate\n",
        "learning_rate = 0.005\n",
        "# define your optimizer with SGD and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "# define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# set the epoch\n",
        "epochs = 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tanApyqYSpRX"
      },
      "source": [
        "# 5. Train the network\n",
        "When all things are ready, we can train the network now.\n",
        "\n",
        "When feeding dataset into the network , we calculate the loss and use the gradient to update the weights by minimizing the loss function.\n",
        "We just simply repeat the process several times.\n",
        "\n",
        "Remember that, if you are using Google Colab, you can change it to use GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-yseh38S5Ba"
      },
      "outputs": [],
      "source": [
        "# loop over the dataset multiple times\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  for j, (images,targets) in enumerate(train_loader):\n",
        "\n",
        "    # making predictions\n",
        "    y_pred = model(images)\n",
        "\n",
        "    # calculating loss\n",
        "    loss = criterion(y_pred,targets.reshape(-1))\n",
        "    # backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  if i>10:\n",
        "    optimizer.lr = 0.0005  # reducing the loss to better adjust the dataset\n",
        "  print(loss)\n",
        "  losses.append(loss)\n",
        "\n",
        "print('Complete Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_TmA4U-TBNI"
      },
      "source": [
        "# 6. Making a Prediction for A Sample from Test Set\n",
        "\n",
        "\n",
        "\n",
        "We have trained the network over the training dataset.\n",
        "Now, we can check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "Hence, we can calculate the accuracy of the model on the test data.\n",
        "\n",
        "For the details, let us display an image from the test data firstly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "remPvJuhTF4W"
      },
      "outputs": [],
      "source": [
        "# make a prediction for a sample randomly chose from the test dataset\n",
        "# you can run this part repeatedly, see the classification result from the model\n",
        "import random\n",
        "rand_no = random.randint(0,10000)\n",
        "print(rand_no)\n",
        "\n",
        "x_test, y_test = next(iter(test_loader))  # getting the test data\n",
        "\n",
        "y_pred = (model(x_test).argmax(dim=1))  # predicting\n",
        "\n",
        "label_list = \"T-shirt/Top Trouser PullOver Dress Coat Sandal Shirt Sneaker Bag AnkleBoot\".split()\n",
        "\n",
        "plt.imshow(x_test[rand_no].reshape(28,28),cmap='gray')\n",
        "\n",
        "pred = model(x_test[rand_no].reshape(-1,1,28,28)).argmax()\n",
        "\n",
        "print(\"This is a/an {}\".format(label_list[pred]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26eHSvJ9TITi"
      },
      "source": [
        "# 7. Model Performance Analysis\n",
        "Let us look at how the network performs on the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6nAMTEYTKWy"
      },
      "outputs": [],
      "source": [
        "# compute the accuracy of the model\n",
        "\n",
        "print(\"Accuracy is : \",(y_pred.eq(y_test).sum()/10000.).item()*100,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHP3vjPCTMyw"
      },
      "source": [
        "# 8. Plots loss error\n",
        "\n",
        "We can show the loss information for each epoch.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT975z8YTTii"
      },
      "outputs": [],
      "source": [
        "# plot loss figure\n",
        "\n",
        "lossess = torch.stack(losses, 0)\n",
        "lossess = lossess.detach().numpy()\n",
        "plt.plot(lossess)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4eDiZDKzCJ8"
      },
      "source": [
        "<b>Note:</b>\n",
        "We use the line plots to show epochs along the ``x-axis`` and the loss error on the ``y-axis``.\n",
        "These plots are sometimes called learning curves. These plots can help to diagnose whether the model has over learned, under learned, or is suitably fit to the training dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps2mjbHuTXvz"
      },
      "source": [
        "# Conclusion\n",
        "The model’s accuracy is found to be 86% on the test set.\n",
        "This proves how strong the neural networks are in predicting images.\n",
        "This is because of the parameter sharing ability and edge-detection ability of network layers.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "9c37791b62b9d5c239fb0fc5acdaf3bd7e92ad96e6d57cd91101e1e69e5d3005"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}