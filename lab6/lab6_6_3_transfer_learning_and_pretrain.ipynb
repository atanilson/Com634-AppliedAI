{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHObHaGyzDDv"
      },
      "source": [
        "# 6.3 Transfer Learning\n",
        "\n",
        "In this code, we show how to perform transfer-learning using a pretrained [ResNet18](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html) and the FashionMnist dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6xcbA4nIWmz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# choose cpu or gpu\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeKjndtJSwxS"
      },
      "source": [
        "The expected input for the Resnet18 network is (3, 224, 224) - (Channel, Height, Width)\n",
        "\n",
        "On the other hand, the images of the FashionMNIST dataset have (1, 28, 28)\n",
        "\n",
        "So we need to preprocess the FashionMNIST dataset in order to resize and prepare the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug9pzemBIiQb"
      },
      "outputs": [],
      "source": [
        "# Pre-process\n",
        "my_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # resize height and width\n",
        "        transforms.Grayscale(3),   # channel\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,0.1307,0.1307), (0.3081,0.3081,0.3081)),  # normalization\n",
        "    ])\n",
        "\n",
        "train_set = torchvision.datasets.FashionMNIST(root = './data/FashionMNIST', download = True,\n",
        "                                              train = True, transform = my_transform)\n",
        "test_set = torchvision.datasets.FashionMNIST(root = './data/FashionMNIST', download=True,\n",
        "                                             train = False, transform = my_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z3mTo7cKIuA"
      },
      "outputs": [],
      "source": [
        "# training set shuffle the data\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=256, shuffle=True)\n",
        "# testing set fix the data order\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5TQJobOM3fb"
      },
      "outputs": [],
      "source": [
        "dataset_sizes = {'train': len(train_set), 'val': len(test_set)}\n",
        "class_names = train_set.classes\n",
        "print(dataset_sizes)\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcdmLjybFVhS"
      },
      "source": [
        "Now that we have the datasets and dataloaders, let's just plot some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4D2Bt2PPWlE"
      },
      "outputs": [],
      "source": [
        "# first batch images in test set\n",
        "inputs, labels = next(iter(test_loader))\n",
        "grid_images = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "def no_normalize(im):\n",
        "    im = im.permute(1, 2, 0)\n",
        "    im = im*torch.Tensor([0.1307, 0.1307, 0.1307]) + torch.Tensor([0.3081, 0.3081, 0.3081])\n",
        "    return im\n",
        "\n",
        "# plot figures\n",
        "grid_images = no_normalize(grid_images)\n",
        "plt.title([class_names[x] for x in labels])\n",
        "plt.imshow(grid_images)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxN_LPJcaVvP"
      },
      "source": [
        "There are two common methods of transfer learning:\n",
        "\n",
        "1. **feature extraction**: uses a pre-trained model (in our case ResNet18) as a fixed feature extractor by keeping its convolutional layers **frozen** and only training a new classifier on top;\n",
        "2. **fine-tuning**: instead of keeping the pre-trained model fixed, we unfreeze some or all layers and train them further on the new dataset.\n",
        "\n",
        "Below, we will use these two methods to train our model, and finally conduct a comparative analysis.\n",
        "Let's first define below train and validation methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlpxkB_tHdiv"
      },
      "outputs": [],
      "source": [
        "def validation(model, criterion):\n",
        "    model.eval()   # eval\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    # data loop\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        # count\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += (preds == labels.data).sum()\n",
        "\n",
        "    epoch_loss = running_loss / dataset_sizes['val']\n",
        "    epoch_acc = running_corrects.double() / dataset_sizes['val']\n",
        "\n",
        "    # print training process\n",
        "    print(f'VAL-LOSS: {epoch_loss:.4f}',  f'VAL-ACC: {epoch_acc:.4f} ', end='\\n')\n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFzY2RYLKWSu"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10, cut_train=False):\n",
        "    for epoch in range(num_epochs):\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        print(\n",
        "            f'EPOCH: {epoch+1:0>{len(str(num_epochs))}}/{num_epochs}',\n",
        "            f'LR: {lr:.4f}',\n",
        "            end=' '\n",
        "        )\n",
        "        model.train()  # train\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # data loop\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero gradient\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + parameters update\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # count\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += (preds == labels.data).sum()\n",
        "\n",
        "            if cut_train is True and i == 10:\n",
        "              # if cut_train is True, break after a few interations to speed up\n",
        "              # not the best approach, but necessary\n",
        "              # ideally, you should train using gpu\n",
        "              break\n",
        "\n",
        "        # learning rate adjustment\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes['train']\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes['train']\n",
        "\n",
        "        # print training process\n",
        "        print(\n",
        "            f'LOSS: {epoch_loss:.4f}',\n",
        "            f'ACC: {epoch_acc:.4f} ',\n",
        "            end='\\n'\n",
        "        )\n",
        "        val_loss, val_acc = validation(model, criterion)  # at the end of an epoch, validate\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV6qV1zXW7wk"
      },
      "source": [
        "Resnet18 is relatively deep compared to ordinary one or two-layer convolutional networks, and the Fashion Mnsit dataset is quite large, with a total of 70,000 pictures. We recommend you to use GPU to train the model, but it will still cost for about 5 minutes for each epochs (you can reduce the training epoch to save time)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5CL5Z_w6wVy"
      },
      "source": [
        "\n",
        "`Note: please run the code on GPU colab due to the time consuming of training process.`\n",
        "\n",
        "`You can change the EPOCH for different values. `\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Y0PV-mc0m_"
      },
      "source": [
        "# 1 - Feature Extraction\n",
        "\n",
        "This method freezes the weights of all layers except the fully connected layer, and only trains the fully connected layer after modifying the fully connected layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv12_742RyLV"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model\n",
        "model_conv = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all layers except fully connected layers so that their gradients are not computed in backpropagation\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Get the number of input features of the fully connected layer of resnet18\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "\n",
        "# Adjust the number of output features of the fully connected layer to 10\n",
        "model_conv.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# GPU/CPU\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer which only pass the parameters of the fully connected layer\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "# Define the optimizer adjustment strategy, and reduce the learning rate by 0.1 multiplication factor after every 5 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=5, gamma=0.1)\n",
        "\n",
        "# train\n",
        "fe_val_loss, fe_val_acc = train_model(\n",
        "    model_conv,\n",
        "    criterion,\n",
        "    optimizer_conv,\n",
        "    exp_lr_scheduler,\n",
        "    num_epochs=1,     # 5, 10, ...\n",
        "    cut_train=True  # comment this to use the entire dataset for training!!!\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DlQyu0JcqGg"
      },
      "source": [
        "# 2 - Parameter fine-tuning\n",
        "This method uses pre-trained parameters to initialize our network model, modifies the fully connected layers and then trains all layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh43PhDlQiZZ"
      },
      "outputs": [],
      "source": [
        "# Load the pretrained model\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "\n",
        "# NOTE THE DIFFERENCE HERE: we do not freeze the layers!!!!!!\n",
        "\n",
        "# Get the number of input features of the fully connected layer of resnet18\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# Adjust the number of output features of the fully connected layer to 10\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "# GPU/CPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "# Define the optimizer adjustment strategy, and reduce the learning rate by 0.1 multiplication factor after every 5 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
        "\n",
        "# call the train_model\n",
        "ft_val_loss, ft_val_acc = train_model(\n",
        "    model_ft,\n",
        "    criterion,\n",
        "    optimizer_ft,\n",
        "    exp_lr_scheduler,\n",
        "    num_epochs=1,  # 5, 10, 15....\n",
        "    cut_train=True  # comment this to use the entire dataset for training!!!\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu7xtIbHJN5s"
      },
      "source": [
        "# 3- Trained from Scratch\n",
        "\n",
        "In this part, we train the same model from scratch, that is, without using pre-trained weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQJENviJR2hL"
      },
      "outputs": [],
      "source": [
        "model_ft = models.resnet18(pretrained=False)\n",
        "\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
        "\n",
        "scr_val_loss, scr_val_acc = train_model(\n",
        "    model_ft,\n",
        "    criterion,\n",
        "    optimizer_ft,\n",
        "    exp_lr_scheduler,\n",
        "    num_epochs=1,  # 5, 10, 15, ...\n",
        "    cut_train=True  # comment this to use the entire dataset for training!!!\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot\n",
        "plt.clf()\n",
        "plt.bar([0, 1, 2], [fe_val_acc, ft_val_acc, scr_val_acc])\n",
        "plt.xticks([0, 1, 2], ['Feature Extraction', 'Fine-Tuning', 'Trained from Scratch'])\n",
        "plt.ylabel('Acc')\n",
        "\n",
        "plt.ylim((0.0, 0.4))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "oxfGlJbtsT_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}