{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BffjblcezmvU"
      },
      "source": [
        "# COMP534 Lab session 5\n",
        "\n",
        "In this session, we will:\n",
        "\n",
        "**1.** compare the Batch Gradient Descend (BGD), Stochastic Gradient Descend (SGD) and Mini Batch Gradient Descend (MBGD);\n",
        "\n",
        "**2.** Analyze hyperparameters, which are tunable in training a neural network;\n",
        "\n",
        "**3.** Perform Fashion MNIST classification with Convolutional layers, Batchnormalization and MaxPooling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPQjRS-K9LVZ"
      },
      "source": [
        "## 5-1 (Batch) Gradient Descent\n",
        "\n",
        "The gradient descent algorithm is a very common method in deep learning, which used to optimize the parameters of a model by computing the gradients of an objective function w.r.t the parameters.\n",
        "\n",
        "In order to find the optimal solution, you can try to use the exhaustive method, the divide and conquer method or the greedy algorithm. The gradient descent algorithm is a greedy algorithm. Through continuous iteration, each time the direction with the fastest loss reduction is selected to update the parameters, the local optimal solution can be quickly reached.\n",
        "If the function is a convex function, the local optimal solution is the global optimal solution; if the function is a non-convex function, it may fall into the local optimal solution, or the saddle point where the gradient is 0 in the neural network, thus stopping the iteration.\n",
        "\n",
        "Here we have some artificially generated data and want to train a neural network to approximate a function. When the function is a linear function , we show the iterative update process using batch gradient descend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFsCHWWQurrX"
      },
      "outputs": [],
      "source": [
        "# Batch Gradient Descent (BGD)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# produce the data point with linear function\n",
        "X = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
        "func = 6 * X  # the actual function that we want to estimate through Gradient Descent\n",
        "# Gaussian noise is added to create the variable Y\n",
        "Y = func + 0.4 * torch.randn(X.size())\n",
        "\n",
        "# plot and visualize the data points\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "ax1 = fig.add_subplot(121)\n",
        "\n",
        "ax1.plot(X, Y, 'b*', label='Data Points')\n",
        "ax1.plot(X, func, 'r', label='Function')\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.legend()\n",
        "ax1.grid('True', color='y')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we learn how to approximate the red line/function from the previous graph using GD."
      ],
      "metadata": {
        "id": "dLNYGBSK2tvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the forward function\n",
        "def forward(x):\n",
        "    return w * x + b  # simple linear regression with slope (w) and intercept (b)\n",
        "\n",
        "# define loss function with Mean Square Error (MSE)\n",
        "def criterion(y_pred, y):\n",
        "    return torch.mean((y_pred - y) ** 2)\n",
        "\n",
        "#  initial parameters w (slope) and b (intercept)\n",
        "# w and b are the parameters we want to learn\n",
        "w = torch.tensor(-10.0, requires_grad=True)\n",
        "b = torch.tensor(-20.0, requires_grad=True)\n",
        "\n",
        "#  other parameters\n",
        "step_size = 0.1\n",
        "loss_BGD = []\n",
        "n_iter = 20\n",
        "\n",
        "# Initial predictions\n",
        "print('Predict before training with BGD: x=' + str(4) + ' y=' + str(4*6) + ' prediction=' + str(forward(4.0)))\n",
        "\n",
        "for i in range (n_iter):\n",
        "    # making predictions with forward pass\n",
        "    Y_pred = forward(X)\n",
        "    # calculating the loss between original and predicted data points\n",
        "    loss = criterion(Y_pred, Y)\n",
        "    # storing the calculated loss in a list\n",
        "    loss_BGD.append(loss.item())\n",
        "    # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # updateing the parameters after each iteration\n",
        "    w.data = w.data - step_size * w.grad.data\n",
        "    b.data = b.data - step_size * b.grad.data\n",
        "\n",
        "    # zeroing gradients after each iteration\n",
        "    w.grad.data.zero_()\n",
        "    b.grad.data.zero_()\n",
        "\n",
        "    # priting some values for understanding\n",
        "    if i % 5 == 0:\n",
        "        print('iteration: {}, \\t loss: {}, \\t weight: {}, \\t bias: {}'.format(i, loss.item(), w.item(), b.item()))\n",
        "\n",
        "#Predict y after updating w\n",
        "print('Predict after training with BGD: x=' + str(4) + ' y=' + str(4*6) + ' prediction=' + str(forward(4.0)))"
      ],
      "metadata": {
        "id": "P6a4lBwy1zVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the cost vs the iteration step. We can clearly see how the loss has decreased over time."
      ],
      "metadata": {
        "id": "APEssXP428vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buc7zgBmurrh"
      },
      "outputs": [],
      "source": [
        "# plot the figure (loss_BGD)\n",
        "plt.plot(loss_BGD, label=\"Batch Gradient Descent\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost/Total loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now compare the real function and the learned one. You will see that both lines (the real and the learned one) are very similar to each other, showing that the learning was, in fact, effective."
      ],
      "metadata": {
        "id": "nvfbKG7p3IeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = w.detach().numpy()\n",
        "B = b.detach().numpy()\n",
        "\n",
        "# plot and visualize the data points\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "ax1 = fig.add_subplot(121)\n",
        "\n",
        "ax1.plot(X, Y, 'b*', label='Data Points')\n",
        "ax1.plot(X, func, 'r', alpha=0.5, label='Real Function')\n",
        "ax1.plot(X, X*W+B, 'gray', alpha=0.5, label='Learned Function')\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.legend()\n",
        "ax1.grid('True', color='y')"
      ],
      "metadata": {
        "id": "QDS71ttZ3K_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5YcA65VCKEc"
      },
      "source": [
        "## **2. Stochastic Gradient Descend**\n",
        "Instead of using the gradient mean of **all** samples to update (like in the GD), in each iteration, a sample is randomly selected from N samples, and the weight w is derived using the loss of a single sample to obtain the gradient, and the weight w is calculated and renew. When encountering a saddle point or a local minimum, the random gradient is helpful to help jump out of this area, so that the algorithm can continue to move towards the optimal point.\n",
        "\n",
        "We will use the same data and methods defined before, changing only the Optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLJaxibhDqXu"
      },
      "outputs": [],
      "source": [
        "#  initial parameters w and b\n",
        "w = torch.tensor(-10.0, requires_grad=True)\n",
        "b = torch.tensor(-20.0, requires_grad=True)\n",
        "\n",
        "# other parameters\n",
        "step_size = 0.1\n",
        "n_iter = 50\n",
        "loss_SGD = []\n",
        "\n",
        "# Initial predictions\n",
        "print('Predict before training with SGD: x=' + str(4) + ' y=' + str(4*6) + ' prediction=' + str(forward(4.0)))\n",
        "\n",
        "for i in range (n_iter):\n",
        "    loss_SGD.append(criterion(forward(X), Y).tolist())  # this is NOT necessary! Only calculated because of the plot below\n",
        "    for x, y in zip(X, Y):  # for each sample\n",
        "      # making a pridiction in forward pass\n",
        "      y_hat = forward(x)\n",
        "      # calculating the loss between original and predicted data points\n",
        "      loss = criterion(y_hat, y)\n",
        "      # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
        "      loss.backward()\n",
        "      # updateing the parameters after each iteration\n",
        "      w.data = w.data - step_size * w.grad.data\n",
        "      b.data = b.data - step_size * b.grad.data\n",
        "      # zeroing gradients after each iteration\n",
        "      w.grad.data.zero_()\n",
        "      b.grad.data.zero_()\n",
        "    # priting some values for understanding\n",
        "    if i % 10 == 0:\n",
        "        print('iteration: {}, \\t loss: {}, \\t weight: {}, \\t bias: {}'.format(i, loss.item(), w.item(), b.item()))\n",
        "\n",
        "#Predict y after updating w\n",
        "print('Predict after training with SGD: x=' + str(4) + ' y=' + str(4*6) + ' prediction=' + str(forward(4.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hrb5-BCMurr3"
      },
      "outputs": [],
      "source": [
        "# plot the figure (loss_SGD)\n",
        "plt.plot(loss_SGD, label=\"Batch Gradient Descent\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost/Total loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHY2jBbQurr8"
      },
      "source": [
        "Stochastic gradient descent has very noisy convergence, because using only one data point for one update. That is why you observe fluctuations in the graph for SGD.\n",
        "In batch gradient descent, the loss is updated after all the training samples are processed while the stochastic gradient descent updates the loss after every training sample in the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRwPN2B_ursC"
      },
      "source": [
        "## **3. Mini-Batch Gradient Descend**\n",
        "Instead of a single sample or the whole dataset, a small batches of the dataset is considered and update the parameters accordingly. For a dataset of 100 samples, if the batch size is 4, meaning we have 25 batches. Hence, updates occur 25 times.\n",
        "For more mathmatical details, please refer [website](https://www.baeldung.com/cs/gradient-stochastic-and-mini-batch#:~:text=Mini%20Batch%20Gradient%20Descent%20is,the%20gradients%20for%20each%20batch.&text=is%20a%20hyperparameter%20that%20denotes%20the%20size%20of%20a%20single%20batch.).\n",
        "\n",
        "Again, we will use the same data and methods defined before, changing only how we optimize the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFr17yAJursK"
      },
      "outputs": [],
      "source": [
        "#  initial parameters w and b\n",
        "w = torch.tensor(-10.0, requires_grad=True)\n",
        "b = torch.tensor(-20.0, requires_grad=True)\n",
        "\n",
        "#  other parameters\n",
        "step_size = 0.01\n",
        "loss_MBGD = []\n",
        "n_iter = 20\n",
        "\n",
        "#Initial predictions\n",
        "print('Predict before training with MBGD: x=' + str(4) + ' y=' + str(4*6) + ' prediction=' + str(forward(4.0)))\n",
        "\n",
        "print(\"Size of training set\", len(X))\n",
        "batch_size = 5\n",
        "n_batches = int(len(X) / batch_size)\n",
        "print(\"Amount of batches in total\", n_batches)\n",
        "\n",
        "for epoch in range(n_iter):  # epochs\n",
        "    batch_loss = []\n",
        "    for n_b in range(n_batches):  # iteration over the number of batches\n",
        "        batch_X, batch_y = X[batch_size*n_b:(n_b+1)*batch_size,], Y[batch_size*n_b:(n_b+1)*batch_size,]\n",
        "        # calculating true loss and storing it\n",
        "        Ybatch_pred = forward(batch_X)\n",
        "        loss = criterion(Ybatch_pred, batch_y)\n",
        "        # store the loss in the list\n",
        "        batch_loss.append(loss.item())\n",
        "        # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
        "        loss.backward()\n",
        "        # updateing the parameters after each iteration\n",
        "        w.data = w.data - step_size * w.grad.data\n",
        "        b.data = b.data - step_size * b.grad.data\n",
        "        # zeroing gradients after each iteration\n",
        "        w.grad.data.zero_()\n",
        "        b.grad.data.zero_()\n",
        "    loss_MBGD.append(np.mean(batch_loss))\n",
        "    print('iteration: {}, \\t loss: {}, \\t weight: {}, \\t bias: {}'.format(epoch, loss.item(), w.item(), b.item()))\n",
        "\n",
        "#Predict y after updating w\n",
        "print('Predict after training with MBGD: x=' + str(4) + ' y=' + str(4*6) + ' prediction=' + str(forward(4.0)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the figure (loss_BGD)\n",
        "plt.plot(loss_MBGD, label=\"Mini Batch Gradient Descent\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost/Total loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pkXqh5wp9p9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's compare the convergence curves."
      ],
      "metadata": {
        "id": "0hzIMpzl_ZDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ-8NVrNursN"
      },
      "outputs": [],
      "source": [
        "# plot the figure\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.plot(loss_MBGD, 'b', label=\"Mini Batch Gradient Descent\")\n",
        "# plt.plot(loss_SGD[:20], 'r',label=\"Stochastic Gradient Descent\")\n",
        "plt.plot(loss_BGD, 'g',label=\"Batch Gradient Descent\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cost/Total loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwhDLuFtFA64"
      },
      "source": [
        "For Mini Batch Gradient Descent, it showa the practical convergence by using batch of the data for one update.\n",
        "Compared with Batch Gradient Descent, the mini batch gradient descent can converge faster.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}