{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8d9imfU9s2b"
      },
      "source": [
        "# 5. Hyperparameters and Model Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ix0uYNr96mS"
      },
      "source": [
        "The first two pieces of this—the choice of model and choice of hyperparameters—are perhaps the most important part of using these tools and techniques effectively.\n",
        "In order to make an informed choice, we need a way to *validate* that our model and our hyperparameters are a good fit to the data.\n",
        "While this may sound simple, there are some pitfalls that you must avoid to do this effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDi5DSej988c"
      },
      "source": [
        "## Thinking about Model Validation\n",
        "\n",
        "In principle, model validation is very simple: after choosing a model and its hyperparameters, we can estimate how effective it is by applying it to some of the training data and comparing the prediction to the known value.\n",
        "\n",
        "The following sections first show a naive approach to model validation and why it\n",
        "fails, before exploring the use of holdout sets and cross-validation for more robust\n",
        "model evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4P3hBOh9_Ui"
      },
      "source": [
        "### Model validation the wrong way\n",
        "\n",
        "Let's demonstrate the naive approach to validation using the Iris data.\n",
        "We will start by loading the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lQaiBB_kewo"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tucVnxul-H7v"
      },
      "source": [
        "Next we choose a model and hyperparameters. Here we'll use a *k*-neighbors classifier with ``n_neighbors=1``.\n",
        "This is a very simple and intuitive model that says \"the label of an unknown point is the same as the label of its closest training point:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIT9m-zW-EwT"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcIqTwqE-LfG"
      },
      "source": [
        "Then we train the model, and use it to predict labels for data we already know and compute the fraction of correctly labeled points:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLTA6a3F-NQS"
      },
      "outputs": [],
      "source": [
        "model.fit(X, y)\n",
        "y_model = model.predict(X)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y, y_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMDGcKG6-R9s"
      },
      "source": [
        "We see an accuracy score of 1.0, which indicates that 100% of points were correctly labeled by our model!\n",
        "But is this truly measuring the expected accuracy? Have we really come upon a model that we expect to be correct 100% of the time?\n",
        "\n",
        "As you may have gathered, the answer is no.\n",
        "In fact, this approach contains a fundamental flaw: *it trains and evaluates the model on the same data*.\n",
        "Furthermore, the nearest neighbor model is an *instance-based* estimator that simply stores the training data, and predicts labels by comparing new data to these stored points: except in contrived cases, it will get 100% accuracy *every time!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTi-MUf5-UwS"
      },
      "source": [
        "### Model validation via k-fold cross-validation\n",
        "\n",
        "\n",
        "*K-Fold Cross-validation*; that is, to do a sequence of fits where each subset of the data is used both as a training set and as a validation set.\n",
        "Visually, it might look something like this:\n",
        "\n",
        "![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-2-fold-CV.png?raw=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB7qUSaQypCP"
      },
      "source": [
        "The results of dividing the dataset into training and testing sets may be random. In order to make the evaluation of the model more objective and accurate, cross-validation can be performed. The main idea is to divide the data set into k parts (called k-fold cross-validation) (usually k=5 or 10), take one of the folds as the test set, and the remaining data as the training set. In this way, k groups of samples can be obtained, k scores are calculated on the training set, and the average of these k scores is calculated.\n",
        "\n",
        "k-fold cross-validation can be implemented through the above-mentioned `train_test_split()` function combined with loop statements. However, sklearn provides a more convenient method: the `cross_val_score()` function.\n",
        "\n",
        "```python\n",
        "cross_val_score(estimator, x, y=None, cv=None, n_jobs=1)\n",
        "```\n",
        "\n",
        "- estimator: estimation method object (classifier)\n",
        "- x: data features (Features)\n",
        "- y: data labels (Labels)\n",
        "- cv: several-fold cross-validation\n",
        "- n_jobs: number of cpus working at the same time (-1 means all)\n",
        "\n",
        "Usually only need to set estimator, x , y, cv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcCyEguEyqU0"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# load data\n",
        "iris=load_iris()\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "\n",
        "# kNN using 5 neighbours\n",
        "knn=KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# 5-fold cross validation\n",
        "scores=cross_val_score(knn, x, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(scores)  # 5 values, one for each iteration\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that when we print the `scores`, we have 5 values: one for each iteration of the 5-fold cross-validation algorithm, which uses a different fold for validation and the remaining 4 for training varying these in each iteration.\n",
        "\n",
        "**IMPORTANT**: Cross-validation is not used to improve the accuracy of the model, but to find the appropriate model parameters to prevent overfitting when the data set is small."
      ],
      "metadata": {
        "id": "2oIMtFH-hiLB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0sBx9f1y1qW"
      },
      "source": [
        "Some hyperparameters in the machine learning model need to be adjusted manually. The common method is grid search, that is, to traverse the hyperparameters according to a certain step size within a reasonable range, and observe the effect of the model under each parameter value (usually crossover Verified scoring results). Especially when there are multiple hyperparameters that need to be debugged, the \"grid\" is more intuitive: traverse the hyperparameters and observe the model effect under each parameter combination.\n",
        "\n",
        "Grid search can be implemented through the above-mentioned `cross_val_score()` function combined with loop statements. Take the hyperparameter k in knn as an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsSaLe7ky6RZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "k_range=range(1,31)  # possible values for k in the kNN algorithm\n",
        "k_scores=[]\n",
        "for k in k_range:\n",
        "    knn=KNeighborsClassifier(n_neighbors=k)\n",
        "    scores=cross_val_score(knn, x, y, cv=5, scoring='accuracy')  # for  classification\n",
        "    #loss=-cross_val_score(knn, x, y, cv=5, scoring='mean_squared_error') # for regression\n",
        "    k_scores.append(scores.mean())\n",
        "\n",
        "#plot\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('value of k for knn')\n",
        "plt.ylabel('cross-validated accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Best k for accuracy\n",
        "max_acc = max(k_scores)\n",
        "print(\"Best values for k:\")\n",
        "print([i+1 for i, j in enumerate(k_scores) if j == max_acc])  # index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsDHJiU__kDP"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW2EGBzvA5bR"
      },
      "source": [
        "With the fitted model, we can now compute the predictions of the model on the test dataset. These predictions are used to compute the final metrics, such as confustion matrix (which is plotted with the [`ConfusionMatrixDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)), [`accuracy`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), etc.\n",
        "\n",
        "Let's first split the data (so we can have some test set) and train the modekl."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "knn_best = KNeighborsClassifier(n_neighbors=5)   # one of the best k value\n",
        "knn_best.fit(X_train,y_train)\n",
        "\n",
        "y_pred = knn_best.predict(X_test)"
      ],
      "metadata": {
        "id": "r6F87DrFkI_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLlh_baY7CsL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7Nob6l62usD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEk43-Av5aKc"
      },
      "source": [
        "A `SKLearn` method called [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) is also a commonly used method for outputting model evaluation reports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fe701cu5hYt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}